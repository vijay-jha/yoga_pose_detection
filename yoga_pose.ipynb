{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd07bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679f18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./images\"\n",
    "training_dir = os.path.join(data_dir, \"training\")\n",
    "testing_dir = os.path.join(data_dir, \"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982d8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {\n",
    " 'virabhadrasana_three': 0,\n",
    " 'navasana': 1,\n",
    " 'hanumanasana': 2,\n",
    " 'ardha_pincha_mayurasana': 3,\n",
    " 'baddha_konasana': 4,\n",
    " 'supta_kapotasana': 5,\n",
    " 'phalakasana': 6,\n",
    " 'urdhva_dhanurasana': 7,\n",
    " 'setu_bandha_sarvangasana': 8,\n",
    " 'sivasana': 9,\n",
    " 'padmasana': 10,\n",
    " 'ashta_chandrasana': 11,\n",
    " 'urdhva_mukha_svsnssana': 12,\n",
    " 'camatkarasana': 13,\n",
    " 'utthita_parsvakonasana': 14,\n",
    " 'malasana': 15,\n",
    " 'uttanasana': 16,\n",
    " 'utthita_hasta_padangusthasana': 17,\n",
    " 'adho_mukha_vrksasana': 18,\n",
    " 'ustrasana': 19,\n",
    " 'virabhadrasana_two': 20,\n",
    " 'salamba_bhujangasana': 21,\n",
    " 'ardha_navasana': 22,\n",
    " 'virabhadrasana_one': 23,\n",
    " 'utkatasana': 24,\n",
    " 'ardha_chandrasana': 25,\n",
    " 'ardha_matsyendrasana': 26,\n",
    " 'upavistha_konasana': 27,\n",
    " 'vasisthasana': 28,\n",
    " 'bakasana': 29,\n",
    " 'parsva_virabhadrasana': 30,\n",
    " 'vrksasana': 31,\n",
    " 'adho_mukha_svanasana': 32,\n",
    " 'anjaneyasana': 33,\n",
    " 'pincha_mayurasana': 34,\n",
    " 'paschimottanasana': 35,\n",
    " 'garudasana': 36,\n",
    " 'halasana': 37,\n",
    " 'trikonasana': 38,\n",
    " 'bitilasana': 39,\n",
    " 'balasana': 40,\n",
    " 'eka_pada_rajakapotasana': 41,\n",
    " 'dhanurasana': 42,\n",
    " 'marjaryasana': 43,\n",
    " 'parsvottanasana': 44,\n",
    " 'salamba_sarvangasana': 45,\n",
    " 'alanasana': 46,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e45bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through your dataset folders\n",
    "for class_folder in os.listdir(training_dir):\n",
    "    class_path = os.path.join(training_dir, class_folder)\n",
    "    class_label = class_folder  # You can assign class labels as needed\n",
    "    \n",
    "    if (class_label != '.DS_Store'):\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if (image_file == '.DS_Store'):\n",
    "                continue\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Read the image and extract RGB values            \n",
    "            image = cv.imread(image_path)\n",
    "            image = cv.resize(image, (32, 32))  # Resize to match the input size of the model\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "            # Assuming you want to reshape the data for use with machine learning\n",
    "            data.append(image)\n",
    "            labels.append(mp[class_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59018b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a68b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3de0fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(47, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a72a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', \n",
    "           loss='sparse_categorical_crossentropy', \n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9679f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 6/69 [=>............................] - ETA: 0s - loss: 3.9307 - accuracy: 0.0260     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 11:48:51.919118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 9ms/step - loss: 3.8258 - accuracy: 0.0404\n",
      "Epoch 2/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4898 - accuracy: 0.1202\n",
      "Epoch 3/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9342 - accuracy: 0.2500\n",
      "Epoch 4/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.5624 - accuracy: 0.3512\n",
      "Epoch 5/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2889 - accuracy: 0.4192\n",
      "Epoch 6/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0998 - accuracy: 0.4746\n",
      "Epoch 7/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.9040 - accuracy: 0.5077\n",
      "Epoch 8/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7905 - accuracy: 0.5513\n",
      "Epoch 9/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7055 - accuracy: 0.5622\n",
      "Epoch 10/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6683 - accuracy: 0.5808\n",
      "Epoch 11/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5673 - accuracy: 0.6016\n",
      "Epoch 12/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4854 - accuracy: 0.6234\n",
      "Epoch 13/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4719 - accuracy: 0.6234\n",
      "Epoch 14/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4875 - accuracy: 0.6343\n",
      "Epoch 15/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5269 - accuracy: 0.6543\n",
      "Epoch 16/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4673 - accuracy: 0.6529\n",
      "Epoch 17/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7602 - accuracy: 0.6257\n",
      "Epoch 18/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6922 - accuracy: 0.6570\n",
      "Epoch 19/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6532 - accuracy: 0.6833\n",
      "Epoch 20/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.9356 - accuracy: 0.6797\n",
      "Epoch 21/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0558 - accuracy: 0.6742\n",
      "Epoch 22/25\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.5780 - accuracy: 0.6570\n",
      "Epoch 23/25\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.4290 - accuracy: 0.6942\n",
      "Epoch 24/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.6272 - accuracy: 0.6910\n",
      "Epoch 25/25\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3050 - accuracy: 0.7287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x300246380>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1e52113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 12.6588 - accuracy: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 11:49:06.311819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.658846855163574, 0.4583333432674408]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c91f606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 11:49:10.020044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84a15221",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(el) for el in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e6c6bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6497707e-03, 4.7307836e-08, 7.7292469e-05, ..., 2.3646882e-07,\n",
       "        2.0939799e-06, 5.2299079e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.9668659e-22,\n",
       "        0.0000000e+00, 6.6487349e-33],\n",
       "       [0.0000000e+00, 1.1238220e-26, 8.5458047e-12, ..., 8.3784874e-30,\n",
       "        8.2642203e-28, 8.1525060e-19],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.9042966e-05, ..., 1.2604179e-11,\n",
       "        9.7029004e-03, 5.7352050e-23],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.4330546e-32, 0.0000000e+00],\n",
       "       [5.1900595e-35, 1.4717960e-28, 9.1536757e-11, ..., 1.3922237e-30,\n",
       "        9.9062416e-12, 2.3794124e-12]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2cbba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 32, 12, 26, 4, 6, 2, 6, 16, 26]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3448f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 32, 21, 25, 37, 28, 32, 28, 16, 26])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
